{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1ML Environment Conflict Analysis  Mk.3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKfTH35jpdqTG2XXb5nb4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DorienCF/ML_Environment_Conflict_Analysis/blob/master/ML_Environment_Conflict_Analysis_Mk_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMEK2gLA7P83"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3CNXsFTzPlf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66f8f097-a8a0-4310-d810-6a138862c479"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from numpy.lib.index_tricks import fill_diagonal\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi9XL8Pb7Vd0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFq_lm2Wha7i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAGWHqS8Ign3",
        "outputId": "85c327de-ac81-4af2-e173-efb8ec85cf0d"
      },
      "source": [
        "print(\"Hello, lets change the world!\\n\"  + \"__\\t__\\t__\\t__\\t__\\t__\\t__\\t__\\t__\\t__\\t__\\t\")\n",
        "\n",
        "CSV_COLUMN_NAMES =['CACivLib',\t'CBCivLib',\t'CCCivLib',\t'CDCivLib',\t'CECivLib',\n",
        "                       'CFCivLib',\t'CAMilSpn',\t'CBMilSpn',\t'CCMilSpn',\t'CDMilSpn',\n",
        "                       'CEMilSpn',\t'CFMilSpn','CAGDP',\t'CBGDP',\t'CCGDP',\t'CDGDP',\t'CEGDP',\n",
        "                       'CFGDP','ConflictConfidenceRating']\n",
        "\n",
        "DfTrain = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ML CONFLICT ANALYSIS/Data folder/MLDATATrain.csv - MLDATATrain.csv\",names=CSV_COLUMN_NAMES,header=0,)\n",
        "DfEval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ML CONFLICT ANALYSIS/Data folder/MLDATAEval - MLDATAEval.csv\", names=CSV_COLUMN_NAMES, header=0)\n",
        "y_train = DfTrain.pop('ConflictConfidenceRating')\n",
        "y_eval = DfEval.pop('ConflictConfidenceRating')\n",
        "#print( \"The First data set is as follows:\\n\" + str(DfTrain))\n",
        "#print(\"__\\t__\\t__\\t__\\t__\\t__\\t__\\t__\\t__\\t__\\t__\\t\")\n",
        "## First I need to add the median value for ever 'NaN' Value \n",
        "#DfTrain = DfTrain.astype('float32').dtypes\n",
        "#print(\"__\\t__\\t__\\t__\\t__\\t__\\t__\\t__\\t__\\t__\\t__\\t\")\n",
        "#print(DfTrain['CACivLib'].mean())\n",
        "#print(DfTrain['CACivLib'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, lets change the world!\n",
            "__\t__\t__\t__\t__\t__\t__\t__\t__\t__\t__\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uaGeevX7nFH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs1TCUZyWLHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eef5746-a605-43c8-e6b8-fc26d394828c"
      },
      "source": [
        "\n",
        "        # Replaceing The 'NaN' values for Civil Liberties.\n",
        "DfTrain['CACivLib'] = DfTrain['CACivLib'].fillna(DfTrain['CACivLib'].mean())\n",
        "#mean1 = DfTrain['CACivLib'].mean(); DfTrain['CACivLib'] = DfTrain['CACivLib'].fillna(mean1) \n",
        "mean2 = DfTrain['CBCivLib'].mean(); DfTrain['CBCivLib'] = DfTrain['CBCivLib'].fillna(mean2)\n",
        "mean3 = DfTrain['CCCivLib'].mean(); DfTrain['CBCivLib'] = DfTrain['CBCivLib'].fillna(mean2)\n",
        "mean3 = DfTrain['CCCivLib'].mean(); DfTrain['CCCivLib'] = DfTrain['CCCivLib'].fillna(mean3)\n",
        "mean4 = DfTrain['CDCivLib'].mean(); DfTrain['CDCivLib'] = DfTrain['CDCivLib'].fillna(mean4)\n",
        "mean5 = DfTrain['CECivLib'].mean(); DfTrain['CECivLib'] = DfTrain['CECivLib'].fillna(mean5)\n",
        "mean6 = DfTrain['CFCivLib'].mean(); DfTrain['CFCivLib'] = DfTrain['CFCivLib'].fillna(mean6)\n",
        "        # Replacing the 'NaN' values for % Military Spending.\n",
        "mean7 = DfTrain['CAMilSpn'].mean(); DfTrain['CAMilSpn'] = DfTrain['CAMilSpn'].fillna(mean7)\n",
        "mean8 = DfTrain['CBMilSpn'].mean(); DfTrain['CBMilSpn'] = DfTrain['CBMilSpn'].fillna(mean8)\n",
        "mean9 = DfTrain['CCMilSpn'].mean(); DfTrain['CCMilSpn'] = DfTrain['CCMilSpn'].fillna(mean9)\n",
        "mean10 = DfTrain['CDMilSpn'].mean(); DfTrain['CDMilSpn'] = DfTrain['CDMilSpn'].fillna(mean10)\n",
        "mean11 = DfTrain['CEMilSpn'].mean(); DfTrain['CEMilSpn'] = DfTrain['CEMilSpn'].fillna(mean11)\n",
        "mean12 = DfTrain['CFMilSpn'].mean(); DfTrain['CFMilSpn'] = DfTrain['CFMilSpn'].fillna(mean12)\n",
        "        #Replacing the 'Nan' values for GDP 2010 constant dollars.\n",
        "mean13 = DfTrain['CAGDP'].mean(); DfTrain['CAGDP'] = DfTrain['CAGDP'].fillna(mean13) \n",
        "mean15 = DfTrain['CBGDP'].mean(); DfTrain['CBGDP'] = DfTrain['CBGDP'].fillna(mean15) # yes I notitced I skiped a number opps... :p\n",
        "mean16 = DfTrain['CCGDP'].mean(); DfTrain['CCGDP'] = DfTrain['CCGDP'].fillna(mean16)\n",
        "mean17 = DfTrain['CDGDP'].mean(); DfTrain['CDGDP'] = DfTrain['CDGDP'].fillna(mean17)\n",
        "mean18 = DfTrain['CEGDP'].mean(); DfTrain['CEGDP'] = DfTrain['CEGDP'].fillna(mean18)\n",
        "mean19 = DfTrain['CFGDP'].mean(); DfTrain['CFGDP'] = DfTrain['CFGDP'].fillna(mean19)\n",
        "# Its doing the same thing as above just for the eval data, I know there is probably a for loop that could do this but this was my first idea and the quickest one to build I had.\n",
        "#_________________________________________________________________________________________________________________________________________________________________________\n",
        "\n",
        "mean1 = DfEval['CACivLib'].mean(); DfEval['CACivLib'] = DfEval['CACivLib'].fillna(mean1)\n",
        "mean2 = DfEval['CBCivLib'].mean(); DfEval['CBCivLib'] = DfEval['CBCivLib'].fillna(mean2)\n",
        "mean3 = DfEval['CCCivLib'].mean(); DfEval['CCCivLib'] = DfEval['CCCivLib'].fillna(mean3)\n",
        "mean4 = DfEval['CDCivLib'].mean(); DfEval['CDCivLib'] = DfEval['CDCivLib'].fillna(mean4)\n",
        "mean5 = DfEval['CECivLib'].mean(); DfEval['CECivLib'] = DfEval['CECivLib'].fillna(mean5)\n",
        "mean6 = DfEval['CFCivLib'].mean(); DfEval['CFCivLib'] = DfEval['CFCivLib'].fillna(mean6)\n",
        "        # Replacing the 'NaN' values for % Military Spending.\n",
        "mean7 = DfEval['CAMilSpn'].mean(); DfEval['CAMilSpn'] = DfEval['CAMilSpn'].fillna(mean7)\n",
        "mean8 = DfEval['CBMilSpn'].mean(); DfEval['CBMilSpn'] = DfEval['CBMilSpn'].fillna(mean8)\n",
        "mean9 = DfEval['CCMilSpn'].mean(); DfEval['CCMilSpn'] = DfEval['CCMilSpn'].fillna(mean9)\n",
        "mean10 = DfEval['CDMilSpn'].mean(); DfEval['CDMilSpn'] = DfEval['CDMilSpn'].fillna(mean10)\n",
        "mean11 = DfEval['CEMilSpn'].mean(); DfEval['CEMilSpn'] = DfEval['CEMilSpn'].fillna(mean11)\n",
        "mean12 = DfEval['CFMilSpn'].mean(); DfEval['CFMilSpn'] = DfEval['CFMilSpn'].fillna(mean12)\n",
        "        #Replacing the 'Nan' values for GDP 2010 constant dollars.\n",
        "mean13 = DfEval['CAGDP'].mean(); DfEval['CAGDP'] = DfEval['CAGDP'].fillna(mean13) \n",
        "mean15 = DfEval['CBGDP'].mean(); DfEval['CBGDP'] = DfEval['CBGDP'].fillna(mean15) # yes I notitced I skiped a number opps... :p\n",
        "mean16 = DfEval['CCGDP'].mean(); DfEval['CCGDP'] = DfEval['CCGDP'].fillna(mean16)\n",
        "mean17 = DfEval['CDGDP'].mean(); DfEval['CDGDP'] = DfEval['CDGDP'].fillna(mean17)\n",
        "mean18 = DfEval['CEGDP'].mean(); DfEval['CEGDP'] = DfEval['CEGDP'].fillna(mean18)\n",
        "mean19 = DfEval['CFGDP'].mean(); DfEval['CFGDP'] = DfEval['CFGDP'].fillna(mean19)\n",
        "#_________________________________________________________________________________________________________________________________________________________________________\n",
        "DfTrain.astype('int64').dtypes\n",
        "#DfEval.astype('int64').dtypes# Getting a 'ValueError: Cannot convert non-finite values (NA or inf) to integer' fix the stuff ^\n",
        "print(DfTrain)\n",
        "#_________________________________________________________________________________________________________________________________________________________________________\n",
        "print(\"_______________________________________________________________________________________________________________________________________________________\")\n",
        "print(y_eval)\n",
        "print(\"_______________________________________________________________________________________________________________________________________________________\")\n",
        "print(DfEval)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   CACivLib  CBCivLib  CCCivLib  CDCivLib  ...     CCGDP  CDGDP  CEGDP        CFGDP\n",
            "0       4.5      3.25       2.0       2.5  ...   915.975  355.3  155.0   745.366667\n",
            "1       5.0      4.00       0.0       0.0  ...     0.000    0.0    0.0     0.000000\n",
            "2       5.0      1.00       2.0       5.0  ...  1111.100  729.6  385.4   376.400000\n",
            "3       7.0      7.00       5.0       4.0  ...     2.300   92.0    6.9   745.366667\n",
            "4       1.0      1.00       1.0       1.0  ...  2550.500  599.6  227.7  1859.700000\n",
            "\n",
            "[5 rows x 18 columns]\n",
            "_______________________________________________________________________________________________________________________________________________________\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    0\n",
            "Name: ConflictConfidenceRating, dtype: int64\n",
            "_______________________________________________________________________________________________________________________________________________________\n",
            "   CACivLib  CBCivLib  CCCivLib  ...        CDGDP    CEGDP    CFGDP\n",
            "0         1         2         6  ...    87.400000   1894.1    71.30\n",
            "1         5         7         1  ...  1482.600000     69.9  1231.30\n",
            "2         3         6         7  ...     0.000000      0.0     0.00\n",
            "3         1         6         6  ...   523.333333  18273.2    50.06\n",
            "\n",
            "[4 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLnj2xhgf4vD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8ldMLnZZBYC",
        "outputId": "caead01f-643d-41ba-c991-2f197bc58252"
      },
      "source": [
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    \"\"\"An input function for training or evaluating\"\"\"\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "    #print(dataset)\n",
        "\n",
        "    # Shuffle and repeat if you are in training mode.\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "\n",
        "    return dataset.batch(batch_size)\n",
        "    # Feature columns describe how to use the input.\n",
        "my_feature_columns = []\n",
        "for key in DfEval.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "    # Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
        "#print(\"This is the feature column:\\n\" + str(my_feature_columns) +\"\\n\"+ \"This is my label column:'n\" +str(y_train) )\n",
        "\n",
        "\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    # Two hidden layers of 30 and 10 nodes respectively.\n",
        "    hidden_units=[10,30,30,90,180,90,30,10,2],\n",
        "    # The model must choose between 3 classes.\n",
        "    n_classes=2)\n",
        "# Train the Model.\n",
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(DfTrain, y_train, training=True),\n",
        "    steps=500)\n",
        "# Evaluating The Trained model\n",
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(DfTrain, y_train, training=False))\n",
        "\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
        "\n",
        "\n",
        "# Generate predictions from the model\n",
        "\n",
        "\n",
        "\n",
        "def input_fn(features, batch_size=256):\n",
        "    \"\"\"An input function for prediction.\"\"\"\n",
        "    # Convert the inputs to a Dataset without labels.\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "predictions = classifier.predict(\n",
        "    input_fn=lambda: input_fn(DfEval))\n",
        "\n",
        "for pred_dict, expec in zip(predictions, y_eval): #fix ME!!!\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "    x,y = 0,0\n",
        "    print('This is broken ... Will fix \\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(y_eval[class_id], 100 * probability, expec))\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp6s37smks\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp6s37smks', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp6s37smks/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 4.86934, step = 0\n",
            "INFO:tensorflow:global_step/sec: 133.105\n",
            "INFO:tensorflow:loss = 0.13789548, step = 100 (0.753 sec)\n",
            "INFO:tensorflow:global_step/sec: 154.447\n",
            "INFO:tensorflow:loss = 0.13666207, step = 200 (0.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 152.62\n",
            "INFO:tensorflow:loss = 0.13589182, step = 300 (0.655 sec)\n",
            "INFO:tensorflow:global_step/sec: 156.131\n",
            "INFO:tensorflow:loss = 0.13529547, step = 400 (0.644 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 500...\n",
            "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tmp6s37smks/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 500...\n",
            "INFO:tensorflow:Loss for final step: 0.13478899.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-06T10:10:54Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp6s37smks/model.ckpt-500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.65415s\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-06-10:10:54\n",
            "INFO:tensorflow:Saving dict for global step 500: accuracy = 1.0, accuracy_baseline = 0.6, auc = 1.0, auc_precision_recall = 1.0, average_loss = 0.1353127, global_step = 500, label/mean = 0.4, loss = 0.1353127, precision = 1.0, prediction/mean = 0.30161542, recall = 1.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: /tmp/tmp6s37smks/model.ckpt-500\n",
            "\n",
            "Test set accuracy: 1.000\n",
            "\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp6s37smks/model.ckpt-500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "This is broken ... Will fix \n",
            "Prediction is \"1\" (99.4%), expected \"1\"\n",
            "This is broken ... Will fix \n",
            "Prediction is \"1\" (50.9%), expected \"1\"\n",
            "This is broken ... Will fix \n",
            "Prediction is \"1\" (95.5%), expected \"1\"\n",
            "This is broken ... Will fix \n",
            "Prediction is \"1\" (100.0%), expected \"0\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVhAutk7z3a2",
        "outputId": "de5ee37b-b358-4e8e-e04d-31aa86ab4885"
      },
      "source": [
        "\n",
        "# Generate predictions from the model\n",
        "\n",
        "\n",
        "\n",
        "def input_fn(features, batch_size=256):\n",
        "    \"\"\"An input function for prediction.\"\"\"\n",
        "    # Convert the inputs to a Dataset without labels.\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "predictions = classifier.predict(\n",
        "    input_fn=lambda: input_fn(DfEval))\n",
        "\n",
        "for pred_dict, expec in zip(predictions, y_eval):\n",
        "    #class_id = pred_dict['class_ids'][0]\n",
        "    #probability = pred_dict['probabilities'][class_id]\n",
        "    x,y = 0,0\n",
        "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
        "        y_eval[class_id], 100 * probability, expec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpm2tzksf0/model.ckpt-50000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Prediction is \"1\" (100.0%), expected \"1\"\n",
            "Prediction is \"1\" (100.0%), expected \"1\"\n",
            "Prediction is \"1\" (100.0%), expected \"1\"\n",
            "Prediction is \"1\" (100.0%), expected \"0\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}